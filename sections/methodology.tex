\section{Methodology}
\subsection{Ensure User Privacy and Confidentiality}
For LLM inference, messages need to be raw and unencrypted to ensure processing. This creates privacy concerns, as even with encryption during transmission, the service provider can access the unencrypted data unlike the messaging companies like Whatsapp that uses End to End Encryption \cite{ermoshina2016end}. By privacy as a security problem, you open the door to applying concepts from fields like cybersecurity and cryptography to mitigate these risks. Active research is underway to enhance user privacy in chatbot applications, particularly through techniques such as Secure Multi-Party Computation (MPC) \cite{rathee2024mpc} a framework MARILL, that leverages open-sourced LLMs and introduces
high-level architectural changes during fine-tuning to minimize MPC usage during secure inference. MARILL is demonstrated to be effective in minimizing secure inference costs across MPC settings in exchange for a reasonable accuracy tradeoff. In particular, MARILL-generated models are 2.4 - 11.3x more efficient for secure inference compared to a standard fine-tuned model, and they typically preserve over 90\% relative performance across multiple challenging LLM tasks. Homomorphic Encryption \cite{kimprivacy} and Differential Privacy \cite{singh2024whispered} exhibit a modest increase in perplexity, this is balanced by their significant emphasis on privacy and security.
\subsection{Avoiding Harmful Content}
Implementing safeguards and guardrailing techniques \cite{biswas2023guardrails} should be imperative for the LLM applications. Given that many users of the AI companion app would be vulnerable, such as those with mental health issues, additional precautions are necessary. Protecting these models requires a combination of robust access controls to prevent unauthorized use, careful monitoring of inputs and outputs to detect malicious prompts or harmful responses \cite{ayyamperumal2024current}. The guardrail system should include different measures to guarantee the safe and ethical use of AI models, especially in critical applications. The first safeguard has to be created in a way that it will shield the private information from revelation or misuse of personal and company information. This is done by first recognizing and managing data that is considered as sensitive data like personal identifiers, health information, and proprietary organizational data at various stages of the AI lifecycle including the training phase, the development phase, the testing phase, and the deployment phase. Another important protection measure should be aimed at avoiding the creation or utilization of toxic information in the course of the interaction with the AI system. It also prevents toxic material from being fed into the models or from being output as responses, thus protecting the user from any unsuitable or hazardous material. The last one should be to protect the system from being manipulated through input prompts which are in one way or the other damaging to the system. This safeguard is important to make sure that the AI model is not compromised by instructions that try to change its behavior for malicious purposes. Combined, these guardrails form a strong and flexible safety net that is able to preserve safety, privacy and ethical integrity in different actual life situations. The level of autonomy granted to AI companions must also be carefully examined. As these systems become more advanced and capable of making independent decisions and recommendations, concerns arise about their potential to influence or manipulate human decision-making processes. Clear guidelines and safeguards must be in place to prevent AI companions from overstepping their intended roles or impeding human decision-making processes \cite{jiao2024navigating}.
\subsection{Primary Goal: Reducing Reliance on Virtual Companions}
The end goal of the AI companion app should be to foster healthy relationships and reduce user reliance on the technology over time, especially for vulnerable individuals.  Developing these systems in a manner that that is designed to encourage users to spend more time on the site or application for the sake of generating revenue is wrong and should be clearly prohibited. Functions that promote overuse, for example, notifications intended to bring the user back into the app or gamified elements that motivate users to engage with the app more often, can result in negative consequences. Study of user reviews by Oyebode et al. \cite{oyebode2020using} of popular mental healthcare apps conclude users think app developers care more about making profits than people's health. Hassan et al. \cite{auf2021gamification} identified 13 different gamification techniques in the top 14 mental health apps. Instead, the app should prioritize empowering users by providing tools for emotional support and encouraging human-to-human connections, rather than creating an environment where users become overly dependent on the AI. This entails coming up with features that assist users to learn skills and ways of handling their feelings and problems without the help of other people or other resources. For instance, the app could include such features as; interventions such as mindfulness tools, cognitive behavioral therapy and self reflection activities. By equipping users with these resources, the app assists them in developing the coping mechanisms that are not dependent on the interaction with the AI on a continuous basis. Heston \cite{heston2023safety} concludes current generative AI-based conversational agents are slow to escalate mental health risk scenarios, postponing referral to a human to potentially dangerous levels. In designing the AI companion, the emphasis should be given the improvement of users' personal development and welfare. This includes setting targets, monitoring and rewarding. achievements. The app can provide tools that will enable the users to discover and achieve their individual goals. regardless of whether it is professional, recreational or in the sphere of interpersonal relationships. By aligning with users' bigger life purposes, the application helps them to transform and achieve personal growth and their goals.